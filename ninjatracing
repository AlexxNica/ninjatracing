#!/usr/bin/env python

"""Converts one (or several) .ninja_log files into chrome's about:tracing format

Usage:
    rm $BUILDDIR/.ninja_log && ninja -C $BUILDDIR
    ninjatracing $BUILDDIR/.ninja_log > trace.json

(If you don't have time for a clean build, at least run
`ninja -C $BUILDDIR -t recompact` first.)"""

import json
import sys


class Target:
    """Represents a single line read for a .ninja_log file."""
    def __init__(self, args):
        self.start, self.end, _, self.name, self.hash = args  # Ignore restat.
        self.start = int(self.start)
        self.end = int(self.end)


class Job:
    """Represents a group of targets that have the same hash."""
    def __init__(self, start, end):
        self.start = start
        self.end = end
        self.targets = []


class Threads:
    """Tries to reconstruct the parallelism from a .ninja_log"""
    def __init__(self):
        self.workers = []  # Maps thread id to time that thread is occupied for.

    def alloc(self, job):
        """Places job in an available thread, or adds a new thread."""
        for worker in range(len(self.workers)):
            if self.workers[worker] <= job.start:
                self.workers[worker] = job.end
                return worker
        self.workers.append(job.end)
        return len(self.workers) - 1


def read_targets(log_file):
    """Reads all targets from .ninja_log file |log_file|."""
    with open(log_file, 'r') as f:
        header = f.readline()
        assert header == "# ninja log v5\n", \
               "unrecognized ninja log version %r" % header
        targets = [Target(line.strip().split('\t')) for line in f]
    return targets


def construct_jobs(targets):
    """Merges targets into jobs. Assuming targets have the same hash when they
    are generated by single job.  Returns jobs sorted by start time."""
    jobs = {}
    for target in targets:
        if not target.hash in jobs:
            jobs[target.hash] = Job(target.start, target.end)
        jobs[target.hash].targets.append(target.name)
    return sorted(jobs.values(), key = lambda job: job.start)


def main(argv):
    entries = []
    for pid, log_file in enumerate(argv):
        threads = Threads()
        for job in construct_jobs(read_targets(log_file)):
            entries.append({
                'name': '%0s' % ', '.join(job.targets), 'cat': 'targets',
                'ph': 'X', 'ts': str(job.start * 1000),
                'dur': str((job.end - job.start) * 1000),
                'pid': str(pid), 'tid': str(threads.alloc(job)), 'args': {},
                })
    json.dump(entries, sys.stdout)


if __name__ == '__main__':
    if len(sys.argv) > 1:
        sys.exit(main(sys.argv[1:]))
    print __doc__
